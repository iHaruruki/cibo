# cibo
[![ROS 2 Distro - Humble](https://img.shields.io/badge/ros2-Humble-blue)](https://docs.ros.org/en/humble/)

## ğŸš€ Overview
- Estimating human skeletal structure while eating.
- Estimating a person's state during meals.

## ğŸ“¦ Feature
### Nodes & Topics
```mermaid
flowchart LR
    A([camera_01])
    B([camera_02])
    C([front_camera_node])
    D([top_camera_node])
    E([eating_state_detector_node])
    F([robot_state_publisher])
    G[[TF]]

    H(/camera_01/color/image_raw)
    I(/camera_01/depth/image_raw)
    J(/camera_01/depth/camera_info)
    K(/camera_02/color/image_raw)
    L(/camera_02/depth/image_raw)
    M(/camera_02/depth/camera_info)
    N(/front_camera/annotated_image)
    O(/front_camera/pose_landmarks)
    P(/front_camera/face_landmarks)
    Q(/front_camera/left_hand_landmarks)
    R(/front_camera/right_hand_landmarks)
    S(/top_camera/annotated_image)
    T(/top_camera/left_hand_landmarks)
    U(/top_camera/right_hand_landmarks)
    V(/robot_description)

    A --> H
    A --> I
    A --> J
    H --> C
    I --> C
    J --> C
    C --> N
    C --> O
    C --> P
    C --> Q
    C --> R
    C --> G

    B --> K
    B --> L
    B --> M
    K --> D
    L --> D
    M --> D
    D --> S
    D --> T
    D --> U
    D --> G

    F --> V
    F --> G

    O --> E
    P --> E
    Q --> E
    R --> E
```
### Flowchart
front_camera_depth_node
```mermaid
flowchart TD
  TStart([top_camera_node]) --> TSync[ApproximateTimeSynchronizer]
  TInputs["Sub: /camera_02/color/image_raw\nSub: /camera_02/depth/image_raw\nSub: /camera_02/depth/camera_info"] --> TSync
  TSync --> TColor["Convert color via CvBridge (bgr8)"]
  TSync --> TDepth["Decode depth â†’ meters"]
  TColor --> TROI{ROI enabled?}
  TROI -- Yes --> TCrop["Crop image to ROI"]
  TROI -- No --> TNoCrop["Use full image"]
  TCrop --> TMp["Run MediaPipe Hands"]
  TNoCrop --> TMp
  TMp --> TDraw["Draw hand landmarks â†’ annotated"]
  TMp --> TExtract["Extract arrays: left/right hand"]
  TDraw --> TPubImg["Publish: /top_camera/annotated_image"]
  TExtract --> TPubLm["Publish: /top_camera/left_hand_landmarks, /top_camera/right_hand_landmarks"]
  TDepth --> TProject["Project 2D + depth â†’ 3D (fx, fy, cx, cy)"]
  TExtract --> TProject
  TProject --> TTF["Broadcast TF frames (rate limit by tf_rate_hz)"]
  TDraw --> TGUI["Show ROI window (drag=set, r=reset, q=close)"]
```
front_camera_depth_node
```mermaid
flowchart TD
  FStart([front_camera_node]) --> FSync[ApproximateTimeSynchronizer]
  FInputs["Sub: /camera_01/color/image_raw\nSub: /camera_01/depth/image_raw\nSub: /camera_01/depth/camera_info"] --> FSync
  FSync --> FColor["Convert color via CvBridge (bgr8)"]
  FSync --> FDepth["Decode depth â†’ meters"]
  FColor --> FROI{ROI enabled?}
  FROI -- Yes --> FCrop["Crop image to ROI"]
  FROI -- No --> FNoCrop["Use full image"]
  FCrop --> FMp["Run MediaPipe Holistic + FaceMesh"]
  FNoCrop --> FMp
  FMp --> FDraw["Draw landmarks â†’ annotated"]
  FMp --> FExtract["Extract arrays: pose, face, left/right hand"]
  FDraw --> FPubImg["Publish: /front_camera/annotated_image"]
  FExtract --> FPubLm["Publish: /front_camera/pose_landmarks, /front_camera/face_landmarks, /front_camera/left_hand_landmarks, /front_camera/right_hand_landmarks"]
  FDepth --> FProject["Project 2D + depth â†’ 3D (fx, fy, cx, cy)"]
  FExtract --> FProject
  FProject --> FTF["Broadcast TF frames (rate limit by tf_rate_hz)"]
  FDraw --> FGUI["Show ROI window (drag=set, r=reset, q=close)"]
```
Chewing Count Node
```mermaid
flowchart TD
  A["Start node: eating_state_detector"] --> P["Declare & get parameters\n(ema_alpha, feeding/speaking/chewing thresholds,\nmin_chewing_interval, stability_frames)"]
  P --> Q["Create QoSProfile\n(BEST_EFFORT, depth=5)"]
  Q --> S["Create subscribers\n/front_camera/pose_landmarks\n/front_camera/face_landmarks\n/front_camera/left_hand_landmarks\n/front_camera/right_hand_landmarks"]
  Q --> PUBS_INIT["Create publishers\n/eating_state/current_state\n/eating_state/chewing_count\n/eating_state/dh, /dj, /dm\n/eating_state/metrics"]

  %% Callbacks -> update_state
  S -->|pose_callback / face_callback /\nleft_hand_callback / right_hand_callback| U["update_state()"]

  %% update_state pipeline
  U --> CM["calculate_metrics()\n- dh_r, dh_l, dh = min(dh_r, dh_l)\n- dj = noseâ†”chin distance\n- dm = upper_lipâ†”lower_lip distance\n- MAR = dm / mouth_width\n- mar_ema = EMA(MAR)"]
  CM --> PDM["publish_distance_metrics()\n-> /eating_state/dh, /dj, /dm"]

  %% Determine state
  CM --> DET["determine_eating_state()"]
  DET --> FEED["detect_feeding():\ndh != inf and dh < feeding_threshold"]
  DET --> SPEAK["detect_speaking():\nmar_ema > speaking_threshold\nand not detect_chewing()"]
  DET --> CHEW["detect_chewing():\nmar_ema hysteresis (high/low)\ncycle timing > min_chewing_interval\n-> increment & publish count"]
  FEED --> NEWSTATE["new_state = FEEDING"]
  SPEAK --> NEWSTATE_S["new_state = SPEAKING"]
  CHEW --> NEWSTATE_C["new_state = CHEWING"]
  DET -->|else| NEWSTATE_I["new_state = IDLE"]

  %% State stability & publish
  NEWSTATE --> HIST["state_history.append(new_state)\n(maxlen = stability_frames)"]
  NEWSTATE_S --> HIST
  NEWSTATE_C --> HIST
  NEWSTATE_I --> HIST

  HIST --> STABLE{"all entries equal\nfor stability_frames?"}
  STABLE -- Yes --> SET["current_state := new_state\n(log transition)"]
  STABLE -- No --> KEEP["keep current_state"]

  SET --> PUBALL["Publish current_state -> /eating_state/current_state\nPublish metrics array -> /eating_state/metrics\n(chewing_count is published on updates)"]
  KEEP --> PUBALL
```


## ğŸ› ï¸ Setup
### Setup Camera ([Astra Stereo S U3](https://store.orbbec.com/products/astra-stereo-s-u3?srsltid=AfmBOop-7Cnl_FU8fo6iytP43uBmOZTonKg5eosq_w3jRvFCeXtigKCG))

Please follow link  
[OrbbecSDK_ROS2](https://github.com/orbbec/OrbbecSDK_ROS2.git)
> [!IMPORTANT]
> branch: `main`  
> Use the `main` branch instead of the default `v2-main`  
> ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®`v2-main`ã¯ä½¿ç”¨ã—ãªã„ã§ï¼Œ`main` branchã‚’ä½¿ç”¨ã™ã‚‹  
> 2025-10-14

### Installing dependent packages
Install python packages
```bash
pip3 install -U "numpy==1.26.4" "opencv-python==4.10.0.84"
pip3 install opencv-python mediapipe
```
Install ros packages
```bash
sudo apt install ros-humble-cv-bridge
sudo apt install ros-humble-image-transport
sudo apt install ros-humble-message-filters
```
### Setup cibo Repositories
Clone
```bash
$ cd ~/ros2_ws/src
$ git clone https://github.com/iHaruruki/cibo.git
```
Build
```bash
$ cd ~/ros2_ws
$ colcon build --symlink-install --packages-select cibo
$ source install/setup.bash
```

## ğŸ® How to use
### Fetch
Synchronize your local repository with the remote repository.  
GitHubã‚’æ›´æ–°ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ï¼Œãƒ­ãƒ¼ã‚«ãƒ«ãƒªãƒã‚¸ãƒˆãƒªã¨ãƒªãƒ¢ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã‚’åŒæœŸã•ã›ã‚‹ï¼
```bash
cd ~/ros2_ws/src/cibo
```
```bash
git fetch
git switch feature-nuc36
git pull origin feature-nuc36
```
### Build
```bash
cd ~/ros2_ws
colcon build --symlink-install --packages-select cibo
source install/setup.bash
```
### Camera launch
Run camera
```bash
ros2 launch orbbec_camera multi_camera.launch.py
```
Check the camera connection. / ã‚«ãƒ¡ãƒ©ã®æ¥ç¶šã‚’ç¢ºèªã™ã‚‹ï¼
```bash
ros2 launch cibo rviz.launch.py
```
View images on rviz2 / rviz2ä¸Šã§ç”»åƒã‚’ç¢ºèª  

- Is the Front-Camera video being output to the `Front_camra` window?  
    `Front_camra`ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«Front-Cameraæ˜ åƒãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã‹
- Is the Top-Camera video being output to the `Top_camera` window?  
    `Top_camera`ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«Top-Cameraæ˜ åƒãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã‹

> [!TIP]
> When the camera connection fails and the Front-Camera/Top-Camera positions are reversed.  
> ã‚«ãƒ¡ãƒ©ã®æ¥ç¶šã«å¤±æ•—ã—ãŸå ´åˆ & Front-Camera/Top-Cameraã®ä½ç½®é–¢ä¿‚ãŒé€†ã®å ´åˆ  
> [Multi-Camera](https://github.com/orbbec/OrbbecSDK_ROS2/tree/main?tab=readme-ov-file#multi-camera)  
> Please follow bellow.

- To get the `usb_port` of the camera, plug in the camera and run the following command in the terminal:  
ã‚«ãƒ¡ãƒ©ã® `usb_port` ã‚’å–å¾—ã™ã‚‹ã«ã¯ï¼Œã‚«ãƒ¡ãƒ©ã®USBç«¯å­ã‚’NUCã«æ¥ç¶šã—ï¼Œã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ï¼
```bash
ros2 run orbbec_camera list_devices_node
```
Resultï¼ˆusb port çµæœãŒè¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
```bash
ros2 run orbbec_camera list_devices_node 
[10/14 22:55:59.986415][info][7139][Context.cpp:68] Context created with config: default config!
[10/14 22:55:59.986426][info][7139][Context.cpp:73] Work directory=/home/#######/ros2_ws, SDK version=v1.10.27-20250925-0549823
[10/14 22:55:59.986459][info][7139][LinuxPal.cpp:32] createObPal: create LinuxPal!
[10/14 22:56:00.340029][warning][7139][OpenNIDeviceInfo.cpp:190] New openni device matched.
[10/14 22:56:00.340040][warning][7139][OpenNIDeviceInfo.cpp:190] New openni device matched.
[10/14 22:56:00.340145][info][7139][LinuxPal.cpp:166] Create PollingDeviceWatcher!
[10/14 22:56:00.340186][info][7139][DeviceManager.cpp:15] Current found device(s): (2)
[10/14 22:56:00.340190][info][7139][DeviceManager.cpp:24] 	- Name: SV1301S_U3, PID: 0x0614, SN/ID: , Connection: USB3.0
[10/14 22:56:00.340192][info][7139][DeviceManager.cpp:24] 	- Name: SV1301S_U3, PID: 0x0614, SN/ID: , Connection: USB3.0
[INFO] [1760450160.382261914] [list_device_node]: serial: AY0F7010783
[INFO] [1760450160.382286638] [list_device_node]: usb port: 2-3.2 #check!
[INFO] [1760450160.424122696] [list_device_node]: serial: AY0F7010108
[INFO] [1760450160.424135464] [list_device_node]: usb port: 2-4.2 #check!
```
- Rewrite the camera launch file. / ã‚«ãƒ¡ãƒ©ã®Launchãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãæ›ãˆã‚‹ï¼  
`ros2_ws/src/OrbbecSDK_ROS2/orbbec_camera/launch/multi_camera.launch.py`
```python
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, GroupAction, ExecuteProcess
from launch.launch_description_sources import PythonLaunchDescriptionSource
from launch_ros.actions import Node
from ament_index_python.packages import get_package_share_directory
import os


def generate_launch_description():
    # Include launch files
    package_dir = get_package_share_directory('orbbec_camera')
    launch_file_dir = os.path.join(package_dir, 'launch')
    launch1_include = IncludeLaunchDescription(
        PythonLaunchDescriptionSource(
            os.path.join(launch_file_dir, 'astra_stereo_u3.launch.py')  # replace your camera launch file
        ),
        launch_arguments={
            'camera_name': 'camera_01',
            'usb_port': '2-3.2',    # replace your front camera usb port here
            'device_num': '2',
            'sync_mode': 'standalone'
        }.items()
    )

    launch2_include = IncludeLaunchDescription(
        PythonLaunchDescriptionSource(
            os.path.join(launch_file_dir, 'astra_stereo_u3.launch.py')  # replace your camera launch file
        ),
        launch_arguments={
            'camera_name': 'camera_02',
            'usb_port': '2-4.2',    # replace your top camera usb port here
            'device_num': '2',
            'sync_mode': 'standalone'
        }.items()
    )

    # If you need more cameras, just add more launch_include here, and change the usb_port and device_num

    # Launch description
    ld = LaunchDescription([
        GroupAction([launch1_include]),
        GroupAction([launch2_include]),
    ])

    return ld
```

- Build
```bash
colcon build --symlink-install --packages-select orbbec_camera
```
- Camera connection check!  
[Run camera](#Camera-launch)

### Launch Cibo
```bash
ros2 launch cibo cibo_depth.launch.py
```
How to Select an ROI (Specify the area for skeleton estimation) / ROIé¸æŠæ–¹æ³•ï¼ˆéª¨æ ¼æ¨å®šã‚’è¡Œã†ç¯„å›²ã‚’æŒ‡å®šã™ã‚‹ï¼‰
1. After launching the node, the OpenCV window will appear.  
    ãƒãƒ¼ãƒ‰èµ·å‹•å¾Œï¼ŒOpenCVã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
2. Drag the mouse to specify the area for skeleton estimation.  
    ãƒã‚¦ã‚¹ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦éª¨æ ¼æ¨å®šã‚’è¡Œã†ç¯„å›²ã‚’æŒ‡å®šã—ã¾ã™
3. A blue rectangle will appear while you drag, and a green rectangle will appear after you confirm.  
    ãƒ‰ãƒ©ãƒƒã‚°ä¸­ã¯é’ã„çŸ©å½¢ãŒè¡¨ç¤ºã•ã‚Œï¼Œç¢ºå®šå¾Œã¯ç·‘ã®çŸ©å½¢ã§è¡¨ç¤ºã•ã‚Œã¾ã™

### View the output image.(OpenCV Image Show) / å‡ºåŠ›ç”»åƒã‚’è¦‹ã‚‹
```bash
ros2 run cibo image_show_node
```
### Run chewing count node
```bash
ros2 run cibo chew_counter_node
```
> [!WARNING]
> `ros2 run cibo chew_counter_node`  
> It may not function properly as it is currently being adjusted.  
> èª¿æ•´ä¸­ã®ãŸã‚ï¼Œæ­£å¸¸ã«å‹•ä½œã—ãªã„ï¼

### Run eating state node 
```bash
ros2 run cibo eating_state_detector_node
```
> [!WARNING]
> `ros2 run cibo chew_counter_node`  
> It may not function properly as it is currently being adjusted.  
> èª¿æ•´ä¸­ã®ãŸã‚ï¼Œæ­£å¸¸ã«å‹•ä½œã—ãªã„ï¼

### [rosbag](https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html)
If you want to record images, use rosbg. / ç”»åƒã‚’éŒ²ç”»ã—ãŸã„å ´åˆã¯ï¼Œrosbagã‚’åˆ©ç”¨
```bash
# make bag_files directory
cd ~/ros2_ws/bag_files
# If you have created it, use `mkdir bag_files`
```
Recode all topic
```bash
ros2 bag record -a
# This command is mode that record all topic.
```
Recode only specific topics
```bash
# ros2 bag record --topics <topic_name_1> <topic_name_2> <topic_name_3>
ros2 bag record --topics /camera_01/color/image_raw /camera_01/depth/image_raw /camera_02/color/image_raw /camera_02/depth/image_raw
```
Recode 
> [!WARNING]
> ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ï¼Œã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç©ºãå®¹é‡ã«æ³¨æ„ï¼


## ğŸš€ Node List

### front_camera_node
- **èª¬æ˜**: ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ç”¨ã®éª¨æ ¼æ¨å®šãƒãƒ¼ãƒ‰.Face Meshãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è©³ç´°ãªé¡”è§£æã‚’å®Ÿè¡Œ

### top_camera_node  
- **èª¬æ˜**: ãƒˆãƒƒãƒ—ã‚«ãƒ¡ãƒ©ç”¨ã®éª¨æ ¼æ¨å®šãƒãƒ¼ãƒ‰.ãƒãƒ¼ã‚ºã¨æ‰‹ã®æ¤œå‡ºã«ç‰¹åŒ–

### chew_counter_node
- **èª¬æ˜**: å’€åš¼å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
- [methods](documents/chewing_count.md)

## eating_state_detection
**èª¬æ˜**: çŠ¶æ…‹æ¨å®š
- [methods](documents/chewing_count.md)

## ğŸ§© Topic List

### front_camera_node

#### Subscribed Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/camera_02/color/image_raw` | `sensor_msgs/Image` | ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®å…¥åŠ›ç”»åƒ |

#### Published Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/front_camera/annotated_image` | `sensor_msgs/Image` | ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ä»˜ãã®ç”»åƒ |
| `/front_camera/pose_landmarks` | `std_msgs/Float32MultiArray` | ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |
| `/front_camera/face_landmarks` | `std_msgs/Float32MultiArray` | é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆFace Meshãƒ¢ãƒ‡ãƒ«ã€æœ€å¤§478ãƒã‚¤ãƒ³ãƒˆã€è™¹å½©å«ã‚€ï¼‰ |
| `/front_camera/left_hand_landmarks` | `std_msgs/Float32MultiArray` | å·¦æ‰‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |
| `/front_camera/right_hand_landmarks` | `std_msgs/Float32MultiArray` | å³æ‰‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |

### top_camera_node

#### Subscribed Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/camera_01/color/image_raw` | `sensor_msgs/Image` | ãƒˆãƒƒãƒ—ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®å…¥åŠ›ç”»åƒ |

#### Published Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/top_camera/annotated_image` | `sensor_msgs/Image` | ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ä»˜ãã®ç”»åƒ |
| `/top_camera/pose_landmarks` | `std_msgs/Float32MultiArray` | ãƒãƒ¼ã‚ºãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |
| `/top_camera/left_hand_landmarks` | `std_msgs/Float32MultiArray` | å·¦æ‰‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |
| `/top_camera/right_hand_landmarks` | `std_msgs/Float32MultiArray` | å³æ‰‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆx,y,zï¼‰ |

### chew_counter_node
#### Subscribed Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/front_camera/face_landmarks` | `std_msgs/Float32MultiArray` | é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯åº§æ¨™ï¼ˆFace Meshãƒ¢ãƒ‡ãƒ«ã€æœ€å¤§478ãƒã‚¤ãƒ³ãƒˆã€è™¹å½©å«ã‚€ï¼‰ |

#### Published Topics
| Topicå | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‹ | èª¬æ˜ |
|---------|-------------|------|
| `/chewing/count` | `std_msgs/Int32` | å’€åš¼ã®ç´¯ç©å›æ•° |
| `/chewing/mar` | `std_msgs/Float32` | å¹³æ»‘åŒ–å¾ŒMAR |

## ğŸ“¦ Parameter List ([ROS 2 params](https://docs.ros.org/en/humble/Concepts/Basic/About-Parameters.html))

### front_camera_node

| Parameterå | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | èª¬æ˜ |
|-------------|----|-----------|----|
| `enable_roi` | bool | true | ROIï¼ˆé–¢å¿ƒé ˜åŸŸï¼‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹ |
| `roi_x` | int | 0 | ROIã®é–‹å§‹Xåº§æ¨™ |
| `roi_y` | int | 0 | ROIã®é–‹å§‹Yåº§æ¨™ |
| `roi_width` | int | 400 | ROIã®å¹… |
| `roi_height` | int | 300 | ROIã®é«˜ã• |
| `min_detection_confidence` | double | 0.5 | æ¤œå‡ºã®æœ€å°ä¿¡é ¼åº¦ |
| `min_tracking_confidence` | double | 0.5 | è¿½è·¡ã®æœ€å°ä¿¡é ¼åº¦ |
| `enable_iris` | bool | true | è™¹å½©æ¤œå‡ºã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹ |
| `refine_landmarks` | bool | true | é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®è©³ç´°åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹ |

### top_camera_node

| Parameterå | å‹ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | èª¬æ˜ |
|-------------|----|-----------|----|
| `enable_roi` | bool | true | ROIï¼ˆé–¢å¿ƒé ˜åŸŸï¼‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹ |
| `roi_x` | int | 0 | ROIã®é–‹å§‹Xåº§æ¨™ |
| `roi_y` | int | 0 | ROIã®é–‹å§‹Yåº§æ¨™ |
| `roi_width` | int | 400 | ROIã®å¹… |
| `roi_height` | int | 300 | ROIã®é«˜ã• |
| `min_detection_confidence` | double | 0.5 | æ¤œå‡ºã®æœ€å°ä¿¡é ¼åº¦ |
| `min_tracking_confidence` | double | 0.5 | è¿½è·¡ã®æœ€å°ä¿¡é ¼åº¦ |

## ğŸ‘¤ Authors
- **[iHaruruki](https://github.com/iHaruruki)** â€” Main author & maintainer

## ğŸ“š Reference
Mediapipe Face Mesh
- [MediaPipe](https://chuoling.github.io/mediapipe/)
- [é¡”ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºã‚¬ã‚¤ãƒ‰](https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker?utm_source=chatgpt.com)
- [468ç‚¹ã®3Dãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã€‚åŸºç¤è§£èª¬](https://mediapipe.readthedocs.io/en/latest/solutions/face_mesh.html?utm_source=chatgpt.com)
- [Face Meshã®å®Ÿå‹™çš„ä½¿ã„æ–¹](https://samproell.io/posts/yarppg/yarppg-face-detection-with-mediapipe/?utm_source=chatgpt.com)

MediaPipe Holistic
- [MediaPipe](https://chuoling.github.io/mediapipe/)
- [Holistic Landmarker](https://ai.google.dev/edge/mediapipe/solutions/vision/holistic_landmarker?utm_source=chatgpt.com)
- [Holistic ã®ãƒˆãƒãƒ­ã‚¸ãƒ»ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ã®è§£èª¬](https://research.google/blog/mediapipe-holistic-simultaneous-face-hand-and-pose-prediction-on-device/?utm_source=chatgpt.com)

MediaPipe Pose
- [Pose Landmarker ã‚¬ã‚¤ãƒ‰](https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker?utm_source=chatgpt.com)

Orbbec Astra Stereo S U3
- [OrbbecSDK_ROS2_Docs](https://github.com/orbbec/OrbbecSDK_ROS2_Docs.git)

Cameras and Calibration
- [Cameras and CalibrationGetting Setup](https://industrial-training-master.readthedocs.io/en/latest/_source/session9/Cameras-and-Calibration.html)

ROS 2 message_filters
- [message_filters](https://docs.ros.org/en/rolling/p/message_filters/doc/index.html)
- [ROS 2ï¼ˆrollingï¼‰ã®Pythonãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://docs.ros.org/en/rolling/p/message_filters/doc/Tutorials/Approximate-Synchronizer-Python.html?utm_source=chatgpt.com)

CV Bridge
- [CvBridgeå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython?utm_source=chatgpt.com)
- [image_pipeline](https://docs.ros.org/en/rolling/p/image_pipeline/camera_info.html)
- [Converting between ROS images and OpenCV images (Python)](https://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython?utm_source=chatgpt.com)
- [image_pipeline](https://docs.ros.org/en/rolling/p/image_pipeline/camera_info.html)

tf2_ros / TransformBroadcasterï¼ˆPythonï¼‰
- [Pythonãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ã‚¿ã®å®Ÿè£…](https://docs.ros.org/en/foxy/Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Py.html?utm_source=chatgpt.com)
- [tf2ï¼ˆROS1ï¼‰ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://wiki.ros.org/tf2/Tutorials/Writing%20a%20tf2%20broadcaster%20%28Python%29?utm_source=chatgpt.com)

Mermaid
- [Mermaidå…¬å¼](https://mermaid.js.org/)
- [mermaidã§ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’æã](https://zenn.dev/yuriemori/articles/e097dbd950df86#%E5%9B%B3%E3%81%AE%E7%A8%AE%E9%A1%9E)

LaTex
- [ã¯ã˜ã‚ã¦ã®LaTex: æ•°å¼ã®å…¥åŠ›ã¨ç’°å¢ƒæ§‹ç¯‰](https://guides.lib.kyushu-u.ac.jp/LaTeX-LectureNote/equations)
- [LaTex - ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§](https://yokatoki.sakura.ne.jp/LaTeX/latex.html)
- [æ•°å¼ã®è¨˜è¿°(markdown)](https://docs.github.com/ja/enterprise-cloud@latest/get-started/writing-on-github/working-with-advanced-formatting/writing-mathematical-expressions)

## ğŸ“œ License
The source code is licensed MIT. Please see LICENSE.